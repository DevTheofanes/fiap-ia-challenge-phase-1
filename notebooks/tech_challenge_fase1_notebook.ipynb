{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae07f5b2",
   "metadata": {},
   "source": [
    "\n",
    "# Tech Challenge — Fase 1 Notebook Consolidado\n",
    "## Dados e Modelos • Exploração • Processamento • Modelagem • Treinamento & Avaliação • Interpretação • Limiar • Calibração\n",
    "\n",
    "**Dataset:** Wisconsin Breast Cancer (M/B).  \n",
    "Edite `DATA_PATH` na célula de configuração caso deseje apontar para outro CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Configurações iniciais ===\n",
    "from __future__ import annotations\n",
    "\n",
    "# Caminho para o CSV\n",
    "DATA_PATH = '../data/wisconsin_breast_cancer.csv'\n",
    "\n",
    "# Coluna alvo esperada no dataset (diagnóstico: 'M' ou 'B')\n",
    "TARGET_COL = 'diagnosis'\n",
    "\n",
    "# Colunas de identificação (removidas das features)\n",
    "ID_COLS = ['id', 'ID number', 'Unnamed: 32']  # ajuste conforme seu arquivo\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Imports ===\n",
    "import os, io, warnings, joblib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "try:\n",
    "    import shap  # type: ignore\n",
    "    HAS_SHAP = True\n",
    "except Exception:\n",
    "    HAS_SHAP = False\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier  # type: ignore\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6fffe5",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Dados e Modelos — definição do problema\n",
    "- **Tarefa:** Classificação binária de diagnóstico (*M* vs *B*).\n",
    "- **Objetivo:** Maximizar **recall** da classe *maligna* (reduzir falsos negativos), mantendo boa precisão.\n",
    "- **Métricas principais:** Accuracy, Precision, Recall, F1, ROC AUC; análise de limiar (ROC/PR).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c1234",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Exploração de dados — leitura, inspeção e limpeza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Leitura ===\n",
    "assert os.path.exists(DATA_PATH), f\"Arquivo CSV não encontrado: {DATA_PATH}\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Formato:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72087dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Info seguro\n",
    "buf = io.StringIO()\n",
    "df.info(buf=buf)\n",
    "print(buf.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Estatísticas descritivas (numéricas)\n",
    "display(df.describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd01e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Missing values\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "display(missing[missing > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a377f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribuição da variável alvo\n",
    "target_counts = df[TARGET_COL].value_counts(dropna=False)\n",
    "print(target_counts)\n",
    "target_counts.plot(kind='bar', title='Distribuição da variável alvo (diagnosis)')\n",
    "plt.xlabel('Classe'); plt.ylabel('Contagem'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Limpeza básica\n",
    "cols_to_drop = [c for c in ID_COLS if c in df.columns]\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "for col in num_cols:\n",
    "    if df[col].isna().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Mapeamento do alvo\n",
    "df['target'] = df[TARGET_COL].map({'M': 1, 'B': 0})\n",
    "assert set(df['target'].dropna().unique()).issubset({0,1}), \"Mapeamento do alvo falhou.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a457cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlações com o alvo\n",
    "corr = df.corr(numeric_only=True)\n",
    "target_corr = corr['target'].sort_values(ascending=False)\n",
    "display(target_corr.head(15)); display(target_corr.tail(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ea0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Heatmap simples (matplotlib)\n",
    "N = 12\n",
    "target_abs = df.corr(numeric_only=True)['target'].abs().sort_values(ascending=False)\n",
    "top_features = target_abs.index[1:N+1]\n",
    "subcorr = df[top_features].corr(numeric_only=True).values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "im = ax.imshow(subcorr, interpolation='nearest')\n",
    "ax.set_xticks(range(len(top_features))); ax.set_yticks(range(len(top_features)))\n",
    "ax.set_xticklabels(top_features, rotation=90); ax.set_yticklabels(top_features)\n",
    "ax.set_title('Correlação entre Top Features'); fig.colorbar(im); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e66218",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Processamento de dados médicos — baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141500a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleção de features numéricas e alvo\n",
    "feature_cols = [c for c in df.columns if c not in [TARGET_COL, 'target']]\n",
    "X = df[feature_cols].select_dtypes(include=[np.number])\n",
    "y = df['target']\n",
    "\n",
    "# Split 60/20/20\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=RANDOM_STATE)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=RANDOM_STATE)\n",
    "\n",
    "print({k:v.shape for k,v in {'X_train':X_train,'X_val':X_val,'X_test':X_test}.items()})\n",
    "print({k:float(v.mean()) for k,v in {'y_train':y_train,'y_val':y_val,'y_test':y_test}.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3be3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Baseline: Regressão Logística\n",
    "baseline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=2000, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "])\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "def eval_and_print(name, y_true, y_pred, y_prob=None):\n",
    "    print(f\"== {name} ==\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1:\", f1_score(y_true, y_pred))\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            print(\"ROC AUC:\", roc_auc_score(y_true, y_prob))\n",
    "        except Exception as e:\n",
    "            print(\"ROC AUC: n/d\", e)\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# Val e Teste\n",
    "y_val_pred = baseline.predict(X_val)\n",
    "y_val_prob = baseline.predict_proba(X_val)[:,1]\n",
    "eval_and_print(\"Validação (Baseline LR)\", y_val, y_val_pred, y_val_prob)\n",
    "\n",
    "y_test_pred = baseline.predict(X_test)\n",
    "y_test_prob = baseline.predict_proba(X_test)[:,1]\n",
    "eval_and_print(\"Teste (Baseline LR)\", y_test, y_test_pred, y_test_prob)\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_val, y_val_prob)\n",
    "plt.title(\"ROC — Validação (Baseline LR)\"); plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_val, y_val_prob)\n",
    "plt.title(\"Precision-Recall — Validação (Baseline LR)\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d9b779",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Modelagem — comparação de algoritmos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c57927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    'LR': Pipeline([('scaler', StandardScaler()),\n",
    "                    ('clf', LogisticRegression(max_iter=2000, class_weight='balanced', random_state=RANDOM_STATE))]),\n",
    "    'SVC': Pipeline([('scaler', StandardScaler()),\n",
    "                     ('clf', SVC(probability=True, class_weight='balanced', random_state=RANDOM_STATE))]),\n",
    "    'RF': Pipeline([('clf', RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, class_weight='balanced'))]),\n",
    "    'KNN': Pipeline([('scaler', StandardScaler()),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=9))]),\n",
    "}\n",
    "if HAS_XGB:\n",
    "    models['XGB'] = Pipeline([('clf', XGBClassifier(\n",
    "        n_estimators=400, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9,\n",
    "        reg_lambda=1.0, n_jobs=4, random_state=RANDOM_STATE, eval_metric='logloss'\n",
    "    ))])\n",
    "\n",
    "# Validação cruzada nos dados de treino\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_results = []\n",
    "for name, pipe in models.items():\n",
    "    acc = cross_val_score(pipe, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "    f1 = cross_val_score(pipe, X_train, y_train, scoring='f1', cv=cv)\n",
    "    rec = cross_val_score(pipe, X_train, y_train, scoring='recall', cv=cv)\n",
    "    cv_results.append({'model': name, 'cv_accuracy_mean': acc.mean(), 'cv_f1_mean': f1.mean(), 'cv_recall_mean': rec.mean()})\n",
    "cv_df = pd.DataFrame(cv_results).sort_values(by=['cv_f1_mean','cv_recall_mean'], ascending=False)\n",
    "display(cv_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3974d90",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Treinamento & Avaliação — tuning + seleção do melhor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997773ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Espaços de busca enxutos\n",
    "param_grids = {\n",
    "    'LR': {'clf__C': [0.1, 1.0, 3.0]},\n",
    "    'SVC': {'clf__C': [0.5, 1.0, 2.0], 'clf__gamma': ['scale', 0.1, 0.01]},\n",
    "    'RF': {'clf__n_estimators': [200, 400], 'clf__max_depth': [None, 4, 8]},\n",
    "    'KNN': {'clf__n_neighbors': [5, 9, 15]}\n",
    "}\n",
    "if HAS_XGB:\n",
    "    param_grids['XGB'] = {'clf__n_estimators': [200, 400], 'clf__max_depth': [3, 4, 5], 'clf__learning_rate': [0.05, 0.1]}\n",
    "\n",
    "best_models = {}\n",
    "for name, base in models.items():\n",
    "    grid = GridSearchCV(base, param_grids.get(name, {}), scoring='f1', cv=3, n_jobs=-1, refit=True)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(f\"{name} -> best params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ec906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleção com base no conjunto de validação\n",
    "def metrics_table(model_name, y_true, y_pred, y_prob):\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_prob) if y_prob is not None else np.nan,\n",
    "    }\n",
    "\n",
    "val_rows = []\n",
    "for name, mdl in best_models.items():\n",
    "    y_pred = mdl.predict(X_val)\n",
    "    y_prob = mdl.predict_proba(X_val)[:,1] if hasattr(mdl, \"predict_proba\") else None\n",
    "    val_rows.append(metrics_table(name, y_val, y_pred, y_prob))\n",
    "\n",
    "val_df = pd.DataFrame(val_rows).sort_values(by=['f1','recall','accuracy'], ascending=False)\n",
    "display(val_df)\n",
    "best_name = val_df.iloc[0]['model']\n",
    "print(\"Melhor modelo pela validação:\", best_name)\n",
    "best_estimator = best_models[best_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Teste final do melhor modelo (padrão limiar 0.5)\n",
    "if hasattr(best_estimator, \"predict_proba\"):\n",
    "    y_test_prob_best = best_estimator.predict_proba(X_test)[:,1]\n",
    "else:\n",
    "    if hasattr(best_estimator, \"decision_function\"):\n",
    "        scores = best_estimator.decision_function(X_test)\n",
    "        smin, smax = scores.min(), scores.max()\n",
    "        y_test_prob_best = (scores - smin) / (smax - smin + 1e-9)\n",
    "    else:\n",
    "        y_test_prob_best = None\n",
    "\n",
    "y_test_pred_best = best_estimator.predict(X_test)\n",
    "\n",
    "print(\"== TESTE (melhor modelo, limiar 0.5) ==\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_best))\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_best))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_best))\n",
    "print(\"F1:\", f1_score(y_test, y_test_pred_best))\n",
    "if y_test_prob_best is not None:\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, y_test_prob_best))\n",
    "print(\"\\nClassification Report (teste):\\n\", classification_report(y_test, y_test_pred_best, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred_best)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm)\n",
    "ax.set_title(f'Matriz de Confusão — Teste ({best_name}, limiar 0.5)')\n",
    "ax.set_xlabel('Predito'); ax.set_ylabel('Verdadeiro')\n",
    "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "ax.set_xticklabels(['Benigno (0)', 'Maligno (1)']); ax.set_yticklabels(['Benigno (0)', 'Maligno (1)'])\n",
    "for (i, j), z in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(z), ha='center', va='center')\n",
    "fig.colorbar(im); plt.show()\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_test_prob_best)\n",
    "plt.title(f\"ROC — Teste ({best_name})\"); plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_test_prob_best)\n",
    "plt.title(f\"Precision-Recall — Teste ({best_name})\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3980999b",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Curva de aprendizado (over/underfitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71454299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_estimator, X_train, y_train, cv=5, scoring='f1',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5), n_jobs=-1\n",
    ")\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, train_mean, marker='o', label='Treino (F1)')\n",
    "plt.plot(train_sizes, val_mean, marker='s', label='Validação (F1)')\n",
    "plt.title(f'Curva de Aprendizado — {best_name}')\n",
    "plt.xlabel('Tamanho do treino'); plt.ylabel('F1'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5884b9",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Interpretabilidade — SHAP e Permutation Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e142632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Amostra para explicações\n",
    "sample_size = min(150, len(X_val))\n",
    "X_val_sample = X_val.sample(sample_size, random_state=RANDOM_STATE)\n",
    "\n",
    "HAS_SHAP_VALUES = False\n",
    "if HAS_SHAP:\n",
    "    try:\n",
    "        # Função de previsão contínua\n",
    "        if hasattr(best_estimator, \"predict_proba\"):\n",
    "            f = lambda data: best_estimator.predict_proba(pd.DataFrame(data, columns=X.columns))[:,1]\n",
    "        elif hasattr(best_estimator, \"decision_function\"):\n",
    "            def f(data):\n",
    "                scores = best_estimator.decision_function(pd.DataFrame(data, columns=X.columns))\n",
    "                smin, smax = scores.min(), scores.max()\n",
    "                return ((scores - smin) / (smax - smin + 1e-9)).reshape(-1,)\n",
    "        else:\n",
    "            f = lambda data: best_estimator.predict(pd.DataFrame(data, columns=X.columns)).astype(float)\n",
    "\n",
    "        background = X_train.sample(min(200, len(X_train)), random_state=RANDOM_STATE)\n",
    "        explainer = shap.KernelExplainer(f, background, link=\"identity\")\n",
    "        shap_values = explainer.shap_values(X_val_sample, nsamples=200)\n",
    "\n",
    "        shap_abs_mean = np.abs(shap_values).mean(axis=0)\n",
    "        imp = pd.DataFrame({'feature': X.columns, 'mean_abs_shap': shap_abs_mean}).sort_values('mean_abs_shap', ascending=False)\n",
    "        display(imp.head(20))\n",
    "\n",
    "        topn = 15\n",
    "        top_imp = imp.head(topn).iloc[::-1]\n",
    "        plt.figure()\n",
    "        plt.barh(top_imp['feature'], top_imp['mean_abs_shap'])\n",
    "        plt.title('Importância (|SHAP| médio) — Top Features')\n",
    "        plt.xlabel('|SHAP| médio'); plt.ylabel('Feature'); plt.tight_layout(); plt.show()\n",
    "        HAS_SHAP_VALUES = True\n",
    "    except Exception as e:\n",
    "        print(\"Falha SHAP, usando permutation importance. Erro:\", e)\n",
    "\n",
    "if not HAS_SHAP_VALUES:\n",
    "    print(\"SHAP indisponível; seguindo com permutation importance.\")\n",
    "    \n",
    "# Permutation importance (sempre mostramos)\n",
    "try:\n",
    "    r = permutation_importance(best_estimator, X_val, y_val, n_repeats=10, random_state=RANDOM_STATE, scoring='f1')\n",
    "    imp_perm = pd.DataFrame({'feature': X.columns, 'importance_mean': r.importances_mean, 'importance_std': r.importances_std})\n",
    "    imp_perm = imp_perm.sort_values('importance_mean', ascending=False)\n",
    "    display(imp_perm.head(20))\n",
    "\n",
    "    plt.figure()\n",
    "    topn = 15\n",
    "    plot_df = imp_perm.head(topn).iloc[::-1]\n",
    "    plt.barh(plot_df['feature'], plot_df['importance_mean'])\n",
    "    plt.title('Permutation Importance (F1) — Top Features')\n",
    "    plt.xlabel('Importância média'); plt.ylabel('Feature'); plt.tight_layout(); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"Falha em permutation importance:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a1c11b",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Ajuste de limiar (foco em recall para maligno)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pontuações no conjunto de validação\n",
    "if hasattr(best_estimator, \"predict_proba\"):\n",
    "    scores_val = best_estimator.predict_proba(X_val)[:,1]\n",
    "elif hasattr(best_estimator, \"decision_function\"):\n",
    "    s = best_estimator.decision_function(X_val)\n",
    "    smin, smax = s.min(), s.max()\n",
    "    scores_val = (s - smin) / (smax - smin + 1e-9)\n",
    "else:\n",
    "    scores_val = best_estimator.predict(X_val).astype(float)\n",
    "\n",
    "thresholds = np.linspace(0.0, 1.0, 201)\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    y_pred_t = (scores_val >= t).astype(int)\n",
    "    prec = precision_score(y_val, y_pred_t, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred_t, zero_division=0)\n",
    "    rows.append({\n",
    "        'threshold': t,\n",
    "        'accuracy': accuracy_score(y_val, y_pred_t),\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1_score(y_val, y_pred_t, zero_division=0),\n",
    "        'f2': (5*prec*rec) / (4*prec + rec + 1e-9)\n",
    "    })\n",
    "thr_df = pd.DataFrame(rows)\n",
    "\n",
    "TARGET_RECALL = 0.98  # ajuste conforme necessidade\n",
    "best_f2 = thr_df.iloc[thr_df['f2'].idxmax()]\n",
    "candidates = thr_df[thr_df['recall'] >= TARGET_RECALL]\n",
    "best_recall_thr = candidates.iloc[candidates['precision'].idxmax()] if len(candidates) else None\n",
    "\n",
    "display(thr_df.head())\n",
    "print(\"Melhor por F2:\", best_f2.to_dict())\n",
    "if best_recall_thr is not None:\n",
    "    print(f\"Melhor recall >= {TARGET_RECALL}: \", best_recall_thr.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, thr_df['precision'], label='Precision')\n",
    "plt.plot(thresholds, thr_df['recall'], label='Recall')\n",
    "plt.plot(thresholds, thr_df['f1'], label='F1')\n",
    "plt.plot(thresholds, thr_df['f2'], label='F2')\n",
    "plt.title('Métricas vs limiar (validação)')\n",
    "plt.xlabel('Limiar'); plt.ylabel('Score'); plt.legend(); plt.show()\n",
    "\n",
    "final_threshold = float(best_f2['threshold'])\n",
    "print(\"Limiar final escolhido:\", final_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b23f8",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Calibração de probabilidades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923adb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Curva de calibração (validação)\n",
    "if hasattr(best_estimator, \"predict_proba\"):\n",
    "    prob_pos = best_estimator.predict_proba(X_val)[:,1]\n",
    "elif hasattr(best_estimator, \"decision_function\"):\n",
    "    s = best_estimator.decision_function(X_val)\n",
    "    smin, smax = s.min(), s.max()\n",
    "    prob_pos = (s - smin) / (smax - smin + 1e-9)\n",
    "else:\n",
    "    prob_pos = best_estimator.predict(X_val).astype(float)\n",
    "\n",
    "frac_pos, mean_pred = calibration_curve(y_val, prob_pos, n_bins=10, strategy='quantile')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.plot(mean_pred, frac_pos, marker='o')\n",
    "plt.title('Curva de Calibração — Validação')\n",
    "plt.xlabel('Prob. prevista (média no bin)'); plt.ylabel('Fração positiva observada'); plt.show()\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "print(\"Brier score (validação):\", brier_score_loss(y_val, prob_pos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca60abd",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Teste final com limiar customizado + salvamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avaliar no TESTE com limiar escolhido\n",
    "if hasattr(best_estimator, \"predict_proba\"):\n",
    "    test_scores = best_estimator.predict_proba(X_test)[:,1]\n",
    "elif hasattr(best_estimator, \"decision_function\"):\n",
    "    s = best_estimator.decision_function(X_test)\n",
    "    smin, smax = s.min(), s.max()\n",
    "    test_scores = (s - smin) / (smax - smin + 1e-9)\n",
    "else:\n",
    "    test_scores = best_estimator.predict(X_test).astype(float)\n",
    "\n",
    "y_test_pred_thr = (test_scores >= final_threshold).astype(int)\n",
    "\n",
    "print(\"== TESTE (limiar customizado) ==\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_thr))\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_thr, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_thr, zero_division=0))\n",
    "print(\"F1:\", f1_score(y_test, y_test_pred_thr, zero_division=0))\n",
    "print(\"\\nClassification Report (teste):\\n\", classification_report(y_test, y_test_pred_thr, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred_thr)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm)\n",
    "ax.set_title(f'Matriz de Confusão — Teste (limiar {final_threshold:.2f})')\n",
    "ax.set_xlabel('Predito'); ax.set_ylabel('Verdadeiro')\n",
    "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "ax.set_xticklabels(['Benigno (0)', 'Maligno (1)']); ax.set_yticklabels(['Benigno (0)', 'Maligno (1)'])\n",
    "for (i, j), z in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(z), ha='center', va='center')\n",
    "fig.colorbar(im); plt.show()\n",
    "\n",
    "# Persistir modelo, features e limiar\n",
    "bundle_path = 'best_model_with_threshold.joblib'\n",
    "joblib.dump({'model': best_estimator, 'features': list(X.columns), 'threshold': float(final_threshold)}, bundle_path)\n",
    "print(f\"Bundle salvo em: {bundle_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8c2e4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "Notebook v5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
